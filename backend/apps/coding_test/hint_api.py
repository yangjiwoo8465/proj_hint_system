"""
íŒíŠ¸ ì±—ë´‡ API - ì •ì  ì§€í‘œ 6ê°œ + LLM ì§€í‘œ 6ê°œ ì‚¬ìš©
"""
import json
import requests
import os
from pathlib import Path
from rest_framework import status
from rest_framework.decorators import api_view, permission_classes
from rest_framework.permissions import IsAuthenticated
from rest_framework.response import Response
from django.conf import settings
from .models import HintRequest, Problem, AIModelConfig, HintMetrics
from .code_analyzer import analyze_code
from .badge_logic import check_and_award_badges


def load_problem_json():
    """ë¬¸ì œ JSON íŒŒì¼ ë¡œë“œ"""
    json_path = Path(__file__).parent / 'data' / 'problems_final_cleaned.json'
    with open(json_path, 'r', encoding='utf-8-sig') as f:
        return json.load(f)


def format_code_indentation(code_text):
    """
    LLM ì‘ë‹µì—ì„œ ì½”ë“œ ë¸”ë¡ì˜ ë“¤ì—¬ì“°ê¸°ë¥¼ ì •ë¦¬í•©ë‹ˆë‹¤.
    JSON ë¬¸ìì—´ë¡œ ì „ë‹¬ë˜ë©´ì„œ ë“¤ì—¬ì“°ê¸°ê°€ ì‚¬ë¼ì§€ëŠ” ë¬¸ì œë¥¼ ë³´ì •í•©ë‹ˆë‹¤.

    Args:
        code_text: LLMì´ ìƒì„±í•œ ì½”ë“œ ë¬¸ìì—´

    Returns:
        str: ì ì ˆí•œ ë“¤ì—¬ì“°ê¸°ê°€ ì ìš©ëœ ì½”ë“œ
    """
    if not code_text:
        return code_text

    lines = code_text.strip().split('\n')
    formatted_lines = []
    indent_level = 0

    for line in lines:
        stripped = line.strip()
        if not stripped:
            formatted_lines.append('')
            continue

        # ë“¤ì—¬ì“°ê¸° ê°ì†Œ: elif, else, except, finally ë“±
        if stripped.startswith(('elif ', 'else:', 'except', 'except:', 'finally:')):
            indent_level = max(0, indent_level - 1)

        # í˜„ì¬ ì¤„ ì¶”ê°€ (ë“¤ì—¬ì“°ê¸° ì ìš©)
        formatted_lines.append('    ' * indent_level + stripped)

        # ë‹¤ìŒ ì¤„ ë“¤ì—¬ì“°ê¸° ì¦ê°€: def, class, if, for, while, try ë“±ìœ¼ë¡œ ëë‚˜ëŠ” ê²½ìš°
        if stripped.endswith(':'):
            indent_level += 1
        # ë“¤ì—¬ì“°ê¸° ê°ì†Œ: return, break, continue, pass, raiseë¡œ ë¸”ë¡ì´ ëë‚˜ëŠ” ê²½ìš°ë„ ê³ ë ¤
        # (ë‹¨, í•¨ìˆ˜ ë‚´ì—ì„œ returnì´ ë‚˜ì™€ë„ í•¨ìˆ˜ëŠ” ê³„ì†ë˜ë¯€ë¡œ ì¡°ì‹¬í•´ì•¼ í•¨)

    return '\n'.join(formatted_lines)


@api_view(['POST'])
@permission_classes([IsAuthenticated])
def request_hint(request):
    """íŒíŠ¸ ìš”ì²­ API - ë‘ ê°€ì§€ ëª©ì ë³„ íŒíŠ¸ ì œê³µ (ì™„ë£Œ/ìµœì í™”)"""
    problem_id = request.data.get('problem_id')
    user_code = request.data.get('user_code', '')
    previous_hints = request.data.get('previous_hints', [])  # Chain of Hints
    manual_purpose = request.data.get('hint_purpose')  # ê´€ë¦¬ì í™”ë©´ìš© ìˆ˜ë™ ëª©ì  ì„¤ì •

    # AI ì„¤ì • ê°€ì ¸ì˜¤ê¸°
    try:
        ai_config = AIModelConfig.objects.first()
        if not ai_config:
            return Response({
                'success': False,
                'error': 'AI ëª¨ë¸ ì„¤ì •ì´ ì—†ìŠµë‹ˆë‹¤. ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”.'
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)
    except Exception as e:
        return Response({
            'success': False,
            'error': f'AI ì„¤ì • ë¡œë“œ ì‹¤íŒ¨: {str(e)}'
        }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)

    # ë¬¸ì œ JSONì—ì„œ ë¬¸ì œ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
    problems = load_problem_json()
    problem = next((p for p in problems if p['problem_id'] == str(problem_id)), None)

    if not problem:
        return Response({
            'success': False,
            'error': f'ë¬¸ì œ ID {problem_id}ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'
        }, status=status.HTTP_404_NOT_FOUND)

    problem_title = problem.get('title', '')
    problem_description = problem.get('description', '')

    # 2ë‹¨ê³„: ProblemStatus ì¡°íšŒ ë° 3ë‹¨ê³„: hint_purpose ê²°ì •
    hint_purpose = manual_purpose  # ìˆ˜ë™ ì„¤ì •ì´ ìˆìœ¼ë©´ ìš°ì„  ì‚¬ìš©
    if not hint_purpose:
        try:
            from .models import Problem, ProblemStatus
            problem_obj = Problem.objects.filter(problem_id=problem_id).first()
            if problem_obj:
                problem_status = ProblemStatus.objects.filter(
                    user=request.user,
                    problem=problem_obj
                ).first()

                if not problem_status:
                    # ì²« í’€ì´
                    hint_purpose = 'completion'
                elif problem_status.status in ['upgrade', 'upgrading']:
                    # ì—…ê·¸ë ˆì´ë“œ/ì—…ê·¸ë ˆì´ë“œ(í‘¸ëŠ” ì¤‘)
                    hint_purpose = 'optimization'
                elif problem_status.status == 'solved':
                    # ì´ë¯¸ ìµœì  ë‹¬ì„± (ì¶”ê°€ ê°œì„  ì—°ìŠµ)
                    hint_purpose = 'optimization'
                else:
                    # ê¸°ë³¸ê°’
                    hint_purpose = 'completion'
            else:
                hint_purpose = 'completion'
        except Exception as e:
            print(f'Failed to determine hint_purpose: {str(e)}')
            hint_purpose = 'completion'

    # íŒíŠ¸ êµ¬ì„± ê°€ì ¸ì˜¤ê¸° (ì»¤ìŠ¤í…€ ë˜ëŠ” í”„ë¦¬ì…‹)
    preset = request.data.get('preset')  # 'ì´ˆê¸‰', 'ì¤‘ê¸‰', 'ê³ ê¸‰', None
    components = request.data.get('custom_components', {})

    # í”„ë¦¬ì…‹ì´ ì§€ì •ëœ ê²½ìš° ê¸°ë³¸ êµ¬ì„± ì„¤ì •
    if preset == 'ì´ˆê¸‰':
        components = {
            'summary': True, 'libraries': True, 'code_example': True,
            'step_by_step': False, 'complexity_hint': False,
            'edge_cases': False, 'improvements': False
        }
    elif preset == 'ì¤‘ê¸‰':
        components = {
            'summary': True, 'libraries': True, 'code_example': False,
            'step_by_step': False, 'complexity_hint': False,
            'edge_cases': False, 'improvements': False
        }
    elif preset == 'ê³ ê¸‰':
        components = {
            'summary': True, 'libraries': False, 'code_example': False,
            'step_by_step': False, 'complexity_hint': False,
            'edge_cases': False, 'improvements': False
        }

    # 4ë‹¨ê³„: ì •ì  ë¶„ì„ (12ê°œ ë©”íŠ¸ë¦­: ì •ì  6ê°œ + LLM 6ê°œ)
    try:
        static_metrics = analyze_code(user_code, problem_id, execution_results=None)
    except Exception as e:
        print(f'Failed to analyze code: {str(e)}')
        static_metrics = {
            'syntax_errors': 0, 'test_pass_rate': 0.0,
            'execution_time': 0.0, 'memory_usage': 0.0,
            'code_quality_score': 0.0, 'pep8_violations': 0
        }

    try:
        from .code_analyzer import evaluate_code_with_llm
        llm_metrics = evaluate_code_with_llm(user_code, problem_description, static_metrics)
    except Exception as e:
        print(f'Failed to evaluate with LLM: {str(e)}')
        llm_metrics = {
            'algorithm_efficiency': 3,
            'code_readability': 3,
            'edge_case_handling': 3,
            'code_conciseness': 3,
            'test_coverage_estimate': 3,
            'security_awareness': 3
        }

    # 5ë‹¨ê³„: hint_purposeë³„ ë¶„ê¸°
    weak_metrics = []
    purpose_context = ""

    if hint_purpose == 'completion':
        # 5-1. completion: ì½”ë“œë¥¼ 'ë™ì‘'í•˜ê²Œ ë§Œë“¤ê¸°
        if static_metrics['syntax_errors'] > 0:
            purpose_context = """
[íŒíŠ¸ ëª©ì : ì½”ë“œ ì™„ë£Œ]
í˜„ì¬ ì½”ë“œì— ë¬¸ë²• ì˜¤ë¥˜ê°€ ìˆìŠµë‹ˆë‹¤. ë¬¸ë²• ì˜¤ë¥˜ë¥¼ ìˆ˜ì •í•˜ëŠ” íŒíŠ¸ë¥¼ ì œê³µí•˜ì„¸ìš”.
- ì–´ë–¤ ë¬¸ë²• ì˜¤ë¥˜ì¸ì§€ ì„¤ëª…
- ì–´ë–»ê²Œ ìˆ˜ì •í•´ì•¼ í•˜ëŠ”ì§€ êµ¬ì²´ì  ë°©ë²• ì œì‹œ
"""
        else:
            purpose_context = """
[íŒíŠ¸ ëª©ì : ì½”ë“œ ì™„ë£Œ]
ë¬¸ë²• ì˜¤ë¥˜ëŠ” ì—†ìŠµë‹ˆë‹¤. ë‹¤ìŒ ë‹¨ê³„ ë¡œì§ì„ êµ¬í˜„í•˜ë„ë¡ ë•ëŠ” íŒíŠ¸ë¥¼ ì œê³µí•˜ì„¸ìš”.
- ì…ë ¥ì„ ì–´ë–»ê²Œ ì²˜ë¦¬í•´ì•¼ í•˜ëŠ”ì§€
- ì–´ë–¤ ìë£Œêµ¬ì¡°ë¥¼ ì‚¬ìš©í•´ì•¼ í•˜ëŠ”ì§€
- ì¶œë ¥ í˜•ì‹ì€ ì–´ë–»ê²Œ ë§ì¶°ì•¼ í•˜ëŠ”ì§€
"""
    elif hint_purpose == 'optimization':
        # 5-2. optimization: ì½”ë“œë¥¼ 'íš¨ìœ¨ì 'ìœ¼ë¡œ ë§Œë“¤ê¸°
        # 12ê°œ ë©”íŠ¸ë¦­ ì¤‘ ì•½ì  íŒŒì•…
        metric_scores = []

        # ì •ì  ì§€í‘œ ì •ê·œí™” (0-100 â†’ 0-5 ìŠ¤ì¼€ì¼)
        if static_metrics['syntax_errors'] > 0:
            metric_scores.append(('syntax_errors', 1, f"ë¬¸ë²• ì˜¤ë¥˜ {static_metrics['syntax_errors']}ê°œ"))

        test_pass_score = (static_metrics['test_pass_rate'] / 100) * 5
        if test_pass_score < 4:
            metric_scores.append(('test_pass_rate', test_pass_score, f"í…ŒìŠ¤íŠ¸ í†µê³¼ìœ¨ {static_metrics['test_pass_rate']}%"))

        if static_metrics.get('execution_time', 0) > 100:
            exec_score = max(1, 5 - (static_metrics['execution_time'] / 200))
            metric_scores.append(('execution_time', exec_score, f"ì‹¤í–‰ ì‹œê°„ {static_metrics['execution_time']}ms"))

        if static_metrics.get('memory_usage', 0) > 1000:
            mem_score = max(1, 5 - (static_metrics['memory_usage'] / 2000))
            metric_scores.append(('memory_usage', mem_score, f"ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ {static_metrics['memory_usage']}KB"))

        quality_score = (static_metrics['code_quality_score'] / 100) * 5
        if quality_score < 3.5:
            metric_scores.append(('code_quality', quality_score, f"ì½”ë“œ í’ˆì§ˆ {static_metrics['code_quality_score']}/100"))

        if static_metrics['pep8_violations'] > 3:
            pep8_score = max(1, 5 - (static_metrics['pep8_violations'] / 2))
            metric_scores.append(('pep8', pep8_score, f"PEP8 ìœ„ë°˜ {static_metrics['pep8_violations']}ê°œ"))

        # LLM ì§€í‘œ (ì´ë¯¸ 1-5 ìŠ¤ì¼€ì¼)
        for key, value in llm_metrics.items():
            if value < 3.5:
                metric_scores.append((key, value, f"{key}: {value}/5"))

        # ê°€ì¥ ì•½í•œ 1-2ê°œ ë©”íŠ¸ë¦­ ì„ íƒ
        metric_scores.sort(key=lambda x: x[1])
        weak_metrics = metric_scores[:2]

        if weak_metrics:
            weak_desc = "\n".join([f"- {desc}" for _, _, desc in weak_metrics])
            purpose_context = f"""
[íŒíŠ¸ ëª©ì : ì½”ë“œ ìµœì í™”]
í˜„ì¬ ì½”ë“œì˜ ì•½ì :
{weak_desc}

ìœ„ ì•½ì ì„ ê°œì„ í•˜ëŠ” íŒíŠ¸ë¥¼ ì œê³µí•˜ì„¸ìš”:
- êµ¬ì²´ì ì¸ ê°œì„  ë°©ë²•
- ìµœì í™” ê¸°ë²•
- ë¦¬íŒ©í† ë§ ì œì•ˆ
"""
        else:
            purpose_context = """
[íŒíŠ¸ ëª©ì : ì½”ë“œ ìµœì í™”]
í˜„ì¬ ì½”ë“œëŠ” ì´ë¯¸ ìš°ìˆ˜í•©ë‹ˆë‹¤. ì¶”ê°€ ê°œì„  ê°€ëŠ¥ì„±ì„ íƒìƒ‰í•˜ëŠ” íŒíŠ¸ë¥¼ ì œê³µí•˜ì„¸ìš”.
"""

    # 3ë‹¨ê³„: ì´ì „ ì§€í‘œ í‰ê·  ê³„ì‚° (Chain of Hints)
    try:
        problem_obj = Problem.objects.filter(problem_id=problem_id).first()
        if problem_obj:
            previous_metrics = HintMetrics.objects.filter(
                user=request.user,
                problem=problem_obj
            ).order_by('-created_at')[:5]  # ìµœê·¼ 5ê°œ ì§€í‘œ

            if previous_metrics.exists():
                # ì •ì  ì§€í‘œ í‰ê· 
                avg_static = {
                    'syntax_errors': sum(m.syntax_errors for m in previous_metrics) / len(previous_metrics),
                    'test_pass_rate': sum(m.test_pass_rate for m in previous_metrics) / len(previous_metrics),
                    'code_complexity': sum(m.code_complexity for m in previous_metrics) / len(previous_metrics),
                    'code_quality_score': sum(m.code_quality_score for m in previous_metrics) / len(previous_metrics),
                    'algorithm_pattern_match': sum(m.algorithm_pattern_match for m in previous_metrics) / len(previous_metrics),
                    'pep8_violations': sum(m.pep8_violations for m in previous_metrics) / len(previous_metrics),
                }
                # LLM ì§€í‘œ í‰ê· 
                avg_llm = {
                    'algorithm_efficiency': sum(m.algorithm_efficiency for m in previous_metrics) / len(previous_metrics),
                    'code_readability': sum(m.code_readability for m in previous_metrics) / len(previous_metrics),
                    'design_pattern_fit': sum(m.design_pattern_fit for m in previous_metrics) / len(previous_metrics),
                    'edge_case_handling': sum(m.edge_case_handling for m in previous_metrics) / len(previous_metrics),
                    'code_conciseness': sum(m.code_conciseness for m in previous_metrics) / len(previous_metrics),
                    'function_separation': sum(m.function_separation for m in previous_metrics) / len(previous_metrics),
                }
            else:
                avg_static = None
                avg_llm = None
        else:
            avg_static = None
            avg_llm = None
    except Exception as e:
        print(f'Failed to calculate average metrics: {str(e)}')
        avg_static = None
        avg_llm = None

    # ë ˆë²¨ë³„ ìš”ì•½ ìŠ¤íƒ€ì¼ ì •ì˜
    summary_style = ""
    if preset == 'ì´ˆê¸‰':
        summary_style = """
ğŸ’¡ ìš”ì•½ (summary): 1-2ì¤„ë¡œ í•µì‹¬ ê°œë…ì„ ì´ˆë³´ì ì¹œí™”ì ìœ¼ë¡œ ì„¤ëª…
  âš ï¸ ë°˜ë“œì‹œ ì§€ì¼œì•¼ í•  ê·œì¹™:
  - í•„ìš”í•œ í•¨ìˆ˜ëª…ì´ë‚˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ëª…ì„ ì§ì ‘ì ìœ¼ë¡œ ì–¸ê¸‰í•˜ì„¸ìš” (ì˜ˆ: "collections.Counterë¥¼ ì‚¬ìš©í•˜ì—¬ ê° ë¬¸ìì˜ ë¹ˆë„ë¥¼ ì„¸ê³ ...")
  - êµ¬ì²´ì ì¸ ì‘ì—…ì´ ë¬´ì—‡ì¸ì§€ ë‹¨ê³„ë³„ë¡œ ëª…í™•íˆ ì„¤ëª…í•˜ì„¸ìš”
  - "ì–´ë–»ê²Œ"ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ êµ¬ì²´ì ì¸ ë°©ë²•ì„ ì œì‹œí•˜ì„¸ìš”
  - ì¶”ìƒì ì¸ ê°œë…ì´ë‚˜ ì§ˆë¬¸ì€ ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”"""
    elif preset == 'ì¤‘ê¸‰':
        summary_style = """
ğŸ’¡ ìš”ì•½ (summary): 1-2ì¤„ë¡œ í•µì‹¬ ê°œë…ì„ ì¤‘ê¸‰ìì—ê²Œ ì„¤ëª…
  âš ï¸ ë°˜ë“œì‹œ ì§€ì¼œì•¼ í•  ê·œì¹™:
  - í•¨ìˆ˜ëª…ì´ë‚˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ëª…ì„ ì§ì ‘ ì–¸ê¸‰í•˜ì§€ ë§ê³ , ìë£Œêµ¬ì¡°ë‚˜ ì•Œê³ ë¦¬ì¦˜ ê°œë…ìœ¼ë¡œë§Œ ì„¤ëª…í•˜ì„¸ìš” (ì˜ˆ: "í•´ì‹œ í…Œì´ë¸”ì„ í™œìš©í•˜ì—¬ ë¹ˆë„ë¥¼ ì¶”ì í•˜ê³ ...")
  - "ë¬´ì—‡ì„" ì‚¬ìš©í•´ì•¼ í•˜ëŠ”ì§€ì— ì§‘ì¤‘í•˜ì„¸ìš”
  - êµ¬ì²´ì ì¸ í•¨ìˆ˜ëª… ëŒ€ì‹  ê°œë…ì  ì ‘ê·¼ë²•ì„ ì œì‹œí•˜ì„¸ìš”
  - ì§ˆë¬¸ í˜•ì‹ì€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”"""
    elif preset == 'ê³ ê¸‰':
        summary_style = """
ğŸ’¡ ìš”ì•½ (summary): ì†Œí¬ë¼í…ŒìŠ¤ì‹ ì§ˆë¬¸ìœ¼ë¡œ ì‚¬ê³ ë¥¼ ìœ ë„
  âš ï¸ ë°˜ë“œì‹œ ì§€ì¼œì•¼ í•  ê·œì¹™:
  - ë°˜ë“œì‹œ ì§ˆë¬¸ í˜•ì‹ìœ¼ë¡œë§Œ ì‘ì„±í•˜ì„¸ìš” (ë°˜ë“œì‹œ '?'ë¡œ ëë‚˜ì•¼ í•©ë‹ˆë‹¤)
  - ì§ì ‘ì ì¸ ë‹µì´ë‚˜ í•´ê²°ì±…ì„ ì ˆëŒ€ ì œì‹œí•˜ì§€ ë§ˆì„¸ìš”
  - êµ¬ì²´ì ì¸ í•¨ìˆ˜ëª…ì´ë‚˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ëª…ì„ ì ˆëŒ€ ì–¸ê¸‰í•˜ì§€ ë§ˆì„¸ìš”
  - í•™ìŠµìê°€ ìŠ¤ìŠ¤ë¡œ ì‚¬ê³ í•˜ë„ë¡ í•µì‹¬ ì§ˆë¬¸ìœ¼ë¡œë§Œ ìœ ë„í•˜ì„¸ìš” (ì˜ˆ: "ì´ ë¬¸ì œì—ì„œ ì¤‘ë³µ ê³„ì‚°ì„ í”¼í•˜ë ¤ë©´ ì–´ë–¤ ìë£Œêµ¬ì¡°ê°€ í•„ìš”í• ê¹Œìš”?")
  - 2ê°œ ì´ìƒì˜ ì—°ê³„ëœ ì§ˆë¬¸ì„ ì‚¬ìš©í•˜ì—¬ ì‚¬ê³ ì˜ íë¦„ì„ ìœ ë„í•˜ì„¸ìš”"""
    else:
        summary_style = "ğŸ’¡ ìš”ì•½ (summary): 1-2ì¤„ë¡œ í•µì‹¬ ê°œë… ì„¤ëª…"

    # ì»¤ìŠ¤í…€ êµ¬ì„± ê¸°ë°˜ í”„ë¡¬í”„íŠ¸ ìƒì„±
    prompt_components = [summary_style]  # ìš”ì•½ì€ í•­ìƒ í¬í•¨

    if components.get('libraries'):
        prompt_components.append("""ğŸ“š ì‚¬ìš© ë¼ì´ë¸ŒëŸ¬ë¦¬ (libraries): í•„ìš”í•œ Python ë¼ì´ë¸ŒëŸ¬ë¦¬/í•¨ìˆ˜ ëª©ë¡
  âš ï¸ ì¤‘ìš”: ì½”ë“œ ì˜ˆì‹œ(code_example)ì—ì„œ ì‹¤ì œë¡œ ì‚¬ìš©í•˜ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬ë§Œ ì¶”ì²œí•˜ì„¸ìš”
  - ì½”ë“œ ì˜ˆì‹œê°€ ì—†ê±°ë‚˜ í‘œì¤€ ë‚´ì¥ í•¨ìˆ˜ë§Œ ì‚¬ìš©í•œë‹¤ë©´, ì´ í•­ëª©ì€ nullë¡œ ë°˜í™˜í•˜ì„¸ìš”""")
    if components.get('code_example'):
        if preset == 'ê³ ê¸‰':
            prompt_components.append("""ğŸ“ ì½”ë“œ ì˜ˆì‹œ (code_example): í•™ìƒì´ ì‘ì„±í•œ ì½”ë“œì— ì´ì–´ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” í•µì‹¬ ë¡œì§
  âš ï¸ ì¤‘ìš” ê·œì¹™:
  - í•™ìƒì´ ì´ë¯¸ ì‘ì„±í•œ ì½”ë“œëŠ” ì ˆëŒ€ ì¤‘ë³µí•´ì„œ ì œì‹œí•˜ì§€ ë§ˆì„¸ìš”
  - í•™ìƒ ì½”ë“œê°€ í‹€ë ¸ë‹¤ë©´: í‹€ë¦° ë¶€ë¶„ë§Œ ìˆ˜ì •í•˜ëŠ” ë°©ë²• ì œì‹œ
  - í•™ìƒ ì½”ë“œê°€ ë§ë‹¤ë©´: ë‹¤ìŒ ë‹¨ê³„ ë¡œì§ë§Œ ì œì‹œ (ì˜ˆ: ì…ë ¥ ì²˜ë¦¬ í›„ â†’ ê³„ì‚° ë¡œì§)
  - "..."ì´ë‚˜ ìƒëµ ê¸°í˜¸ë¥¼ ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”
  - ì™„ì „í•˜ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ì½”ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”
  - í•¨ìˆ˜ ë¶„ë¦¬ì™€ ì•Œê³ ë¦¬ì¦˜ì  ì‚¬ê³ ë¥¼ ìœ ë„í•˜ëŠ” êµ¬ì¡°ë¡œ ì‘ì„±í•˜ì„¸ìš”
  - ì½”ë“œ ë¸”ë¡ì€ ë°˜ë“œì‹œ ì˜¬ë°”ë¥¸ Python ë“¤ì—¬ì“°ê¸°(4ì¹¸ ìŠ¤í˜ì´ìŠ¤)ë¥¼ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤

  ì˜ˆì‹œ:
  - í•™ìƒ ì½”ë“œ: "a, b = input().split()" (ë§ìŒ)
    â†’ ë‹¤ìŒ ë‹¨ê³„: "# ì…ë ¥ì„ ì •ìˆ˜ë¡œ ë³€í™˜\na, b = int(a), int(b)\n# ê³„ì‚° ë¡œì§\nresult = a + b\nprint(result)"
  - í•™ìƒ ì½”ë“œ: "a, b = input().split()" (í‹€ë¦¼ - ì •ìˆ˜ ë³€í™˜ ëˆ„ë½)
    â†’ ìˆ˜ì •: "a, b = map(int, input().split())  # intë¡œ ë³€í™˜ í•„ìš”" """)
        else:
            prompt_components.append("""ğŸ“ ì½”ë“œ ì˜ˆì‹œ (code_example): ê°„ë‹¨í•œ ì½”ë“œ ì˜ˆì œ (5-10ì¤„, í•µì‹¬ ë¡œì§ í¬í•¨)
  âš ï¸ ì¤‘ìš” ê·œì¹™:
  - í•™ìƒì´ ì´ë¯¸ ì‘ì„±í•œ ì½”ë“œëŠ” ì ˆëŒ€ ì¤‘ë³µí•´ì„œ ì œì‹œí•˜ì§€ ë§ˆì„¸ìš”
  - í•™ìƒ ì½”ë“œê°€ í‹€ë ¸ë‹¤ë©´: í‹€ë¦° ë¶€ë¶„ë§Œ ìˆ˜ì •
  - í•™ìƒ ì½”ë“œê°€ ë§ë‹¤ë©´: ë‹¤ìŒ ë‹¨ê³„ ë¡œì§ë§Œ ì œì‹œ
  - ì½”ë“œ ë¸”ë¡ì€ ë°˜ë“œì‹œ ì˜¬ë°”ë¥¸ Python ë“¤ì—¬ì“°ê¸°(4ì¹¸ ìŠ¤í˜ì´ìŠ¤)ë¥¼ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤""")
    if components.get('step_by_step'):
        prompt_components.append("ğŸ“‹ ë‹¨ê³„ë³„ í•´ê²° ë°©ë²• (step_by_step): ë¬¸ì œ í•´ê²° ë‹¨ê³„ë¥¼ ìˆœì„œëŒ€ë¡œ ë‚˜ì—´")
    if components.get('complexity_hint'):
        prompt_components.append("â±ï¸ ì‹œê°„/ê³µê°„ ë³µì¡ë„ íŒíŠ¸ (complexity_hint): ëª©í‘œ ë³µì¡ë„ì™€ ìµœì í™” ë°©ë²•")
    if components.get('edge_cases'):
        prompt_components.append("âš ï¸ ì—£ì§€ ì¼€ì´ìŠ¤ (edge_cases): ê³ ë ¤í•´ì•¼ í•  íŠ¹ìˆ˜ ì¼€ì´ìŠ¤ ëª©ë¡")
    if components.get('improvements'):
        prompt_components.append("âœ¨ ê°œì„  ì‚¬í•­ (improvements): í˜„ì¬ ì½”ë“œì˜ ê°œì„ ì  ì œì•ˆ")

    components_str = "\n".join(prompt_components)

    # ì´ì „ íŒíŠ¸ ì»¨í…ìŠ¤íŠ¸ ìƒì„± (Chain of Hints)
    previous_hints_str = ""
    if previous_hints:
        hints_list = []
        for i, prev_hint in enumerate(previous_hints, 1):
            hint_text = prev_hint.get('hint_text', '')
            level = prev_hint.get('level', 'ì»¤ìŠ¤í…€')
            timestamp = prev_hint.get('timestamp', '')
            hints_list.append(f"{i}. [{level}] {hint_text[:100]}...")
        previous_hints_str = f"""
# ì´ì „ íŒíŠ¸ ì´ë ¥ (ì°¸ê³ ìš©)
í•™ìƒì´ ì´ë¯¸ ë°›ì€ íŒíŠ¸ë“¤ì…ë‹ˆë‹¤. ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë” ë°œì „ëœ íŒíŠ¸ë¥¼ ì œê³µí•˜ì„¸ìš”:
{chr(10).join(hints_list)}

âš ï¸ ì¤‘ìš”: ìœ„ íŒíŠ¸ë“¤ì—ì„œ ì–¸ê¸‰í•œ ë‚´ìš©ì€ ë°˜ë³µí•˜ì§€ ë§ê³ , ë‹¤ìŒ ë‹¨ê³„ë‚˜ ìƒˆë¡œìš´ ê´€ì ì˜ íŒíŠ¸ë¥¼ ì œê³µí•˜ì„¸ìš”.
"""

    # ì§€í‘œ í‰ê·  ì»¨í…ìŠ¤íŠ¸ ìƒì„± (Chain of Hints)
    metrics_history_str = ""
    if avg_static and avg_llm:
        metrics_history_str = f"""
# ì´ì „ ì§€í‘œ í‰ê·  (ìµœê·¼ 5íšŒ)
í•™ìƒì˜ ì´ì „ ì½”ë“œ í‰ê°€ ê²°ê³¼ì…ë‹ˆë‹¤. í˜„ì¬ ì½”ë“œì™€ ë¹„êµí•˜ì—¬ ê°œì„ /ì•…í™” ì—¬ë¶€ë¥¼ íŒŒì•…í•˜ì„¸ìš”:

## ì •ì  ì§€í‘œ í‰ê· 
- ë¬¸ë²• ì˜¤ë¥˜: {avg_static['syntax_errors']:.1f}ê°œ (í˜„ì¬: {static_metrics['syntax_errors']}ê°œ)
- í…ŒìŠ¤íŠ¸ í†µê³¼ìœ¨: {avg_static['test_pass_rate']:.1f}% (í˜„ì¬: {static_metrics['test_pass_rate']}%)
- ì‹¤í–‰ ì‹œê°„: {avg_static.get('execution_time', 0):.1f}ms (í˜„ì¬: {static_metrics.get('execution_time', 0)}ms)
- ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {avg_static.get('memory_usage', 0):.1f}KB (í˜„ì¬: {static_metrics.get('memory_usage', 0)}KB)
- ì½”ë“œ í’ˆì§ˆ: {avg_static['code_quality_score']:.1f}/100 (í˜„ì¬: {static_metrics['code_quality_score']})
- PEP8 ìœ„ë°˜: {avg_static['pep8_violations']:.1f}ê°œ (í˜„ì¬: {static_metrics['pep8_violations']}ê°œ)

## LLM ì§€í‘œ í‰ê· 
- ì•Œê³ ë¦¬ì¦˜ íš¨ìœ¨ì„±: {avg_llm['algorithm_efficiency']:.1f}/5 (í˜„ì¬: {llm_metrics['algorithm_efficiency']}/5)
- ì½”ë“œ ê°€ë…ì„±: {avg_llm['code_readability']:.1f}/5 (í˜„ì¬: {llm_metrics['code_readability']}/5)
- ì—£ì§€ ì¼€ì´ìŠ¤ ì²˜ë¦¬: {avg_llm['edge_case_handling']:.1f}/5 (í˜„ì¬: {llm_metrics['edge_case_handling']}/5)
- ì½”ë“œ ê°„ê²°ì„±: {avg_llm['code_conciseness']:.1f}/5 (í˜„ì¬: {llm_metrics['code_conciseness']}/5)
- í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€ ì¶”ì •: {avg_llm.get('test_coverage_estimate', 3):.1f}/5 (í˜„ì¬: {llm_metrics.get('test_coverage_estimate', 3)}/5)
- ë³´ì•ˆ ì¸ì‹: {avg_llm.get('security_awareness', 3):.1f}/5 (í˜„ì¬: {llm_metrics.get('security_awareness', 3)}/5)

ğŸ’¡ ê°œì„ ëœ ì§€í‘œëŠ” ì¹­ì°¬í•˜ê³ , ì•…í™”ëœ ì§€í‘œëŠ” êµ¬ì²´ì ì¸ ê°œì„  ë°©í–¥ì„ ì œì‹œí•˜ì„¸ìš”.
"""

    # í†µí•© í”„ë¡¬í”„íŠ¸ ìƒì„± (6ë‹¨ê³„: LLM íŒíŠ¸ ìƒì„±)
    prompt = f"""ë‹¹ì‹ ì€ Python ì½”ë”© êµìœ¡ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

# ë¬¸ì œ ì •ë³´
{problem_description}

# í•™ìƒ ì½”ë“œ
{user_code if user_code else '(ì•„ì§ ì‘ì„±í•˜ì§€ ì•ŠìŒ)'}

{purpose_context}

# í˜„ì¬ ì½”ë“œ ë¶„ì„ ê²°ê³¼ (12ê°œ ì§€í‘œ)

## ì •ì  ì§€í‘œ (6ê°œ)
- ë¬¸ë²• ì˜¤ë¥˜: {static_metrics['syntax_errors']}ê°œ
- í…ŒìŠ¤íŠ¸ í†µê³¼ìœ¨: {static_metrics['test_pass_rate']}%
- ì‹¤í–‰ ì‹œê°„: {static_metrics.get('execution_time', 0)}ms
- ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {static_metrics.get('memory_usage', 0)}KB
- ì½”ë“œ í’ˆì§ˆ ì ìˆ˜: {static_metrics['code_quality_score']}/100
- PEP8 ìœ„ë°˜: {static_metrics['pep8_violations']}ê°œ

## LLM í‰ê°€ ì§€í‘œ (6ê°œ, ê° 1-5ì )
- ì•Œê³ ë¦¬ì¦˜ íš¨ìœ¨ì„±: {llm_metrics['algorithm_efficiency']}/5
- ì½”ë“œ ê°€ë…ì„±: {llm_metrics['code_readability']}/5
- ì—£ì§€ ì¼€ì´ìŠ¤ ì²˜ë¦¬: {llm_metrics['edge_case_handling']}/5
- ì½”ë“œ ê°„ê²°ì„±: {llm_metrics['code_conciseness']}/5
- í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€ ì¶”ì •: {llm_metrics.get('test_coverage_estimate', 3)}/5
- ë³´ì•ˆ ì¸ì‹: {llm_metrics.get('security_awareness', 3)}/5
{metrics_history_str}{previous_hints_str}
# ìš”ì²­ ì‚¬í•­
ìœ„ íŒíŠ¸ ëª©ì ê³¼ 12ê°œ ì§€í‘œë¥¼ ëª¨ë‘ ë°˜ì˜í•˜ì—¬ ë‹¤ìŒ í•­ëª©ë§Œ í¬í•¨í•œ íŒíŠ¸ë¥¼ ì œê³µí•˜ì„¸ìš”:
{components_str}

âš ï¸ ì¤‘ìš”:
- **íŒíŠ¸ ëª©ì ì— ë”°ë¼ ì´ˆì ì„ ë§ì¶”ì„¸ìš”** (ì™„ë£Œ: ë™ì‘í•˜ê²Œ ë§Œë“¤ê¸° / ìµœì í™”: íš¨ìœ¨ì ìœ¼ë¡œ ë§Œë“¤ê¸°)
- 12ê°œ ì§€í‘œë¥¼ ëª¨ë‘ ê³ ë ¤í•˜ì—¬ ì¢…í•©ì ì¸ í”¼ë“œë°±ì„ ì œê³µí•˜ì„¸ìš”
- ì´ì „ ì§€í‘œ í‰ê· ì´ ìˆë‹¤ë©´ ê°œì„ /ì•…í™” ì—¬ë¶€ë¥¼ ëª…í™•íˆ ì–¸ê¸‰í•˜ì„¸ìš”
- ê°€ì¥ ì‹œê¸‰í•œ ê°œì„  ì‚¬í•­ì„ ìš°ì„ ì ìœ¼ë¡œ ë‹¤ë£¨ì„¸ìš”

# ì‘ë‹µ í˜•ì‹ (JSON)
{{
  "hint_content": {{
    "summary": "..." or null,
    "libraries": [...] or null,
    "code_example": "..." or null,
    "step_by_step": [...] or null,
    "complexity_hint": "..." or null,
    "edge_cases": [...] or null,
    "improvements": [...] or null
  }}
}}

ìœ„ êµ¬ì„±ë§Œ í¬í•¨í•˜ì—¬ ì‘ë‹µí•˜ì„¸ìš”. ì„ íƒë˜ì§€ ì•Šì€ í•­ëª©ì€ nullë¡œ ë°˜í™˜í•˜ì„¸ìš”.
"""

    # AI ì„¤ì •ì— ë”°ë¼ íŒíŠ¸ ìƒì„± ë°©ì‹ ê²°ì •
    hint_response = ""

    if ai_config.mode == 'api':
        # API ë°©ì‹: Hugging Face Inference API ì‚¬ìš©
        api_key = ai_config.api_key if ai_config.api_key else os.environ.get('HUGGINGFACE_API_KEY', '')

        # ë””ë²„ê¹…: API í‚¤ ìƒíƒœ ë¡œê¹…
        print(f'[DEBUG] DB API Key exists: {bool(ai_config.api_key)}')
        print(f'[DEBUG] DB API Key length: {len(ai_config.api_key) if ai_config.api_key else 0}')
        print(f'[DEBUG] Final API Key exists: {bool(api_key)}')
        print(f'[DEBUG] Model: {ai_config.model_name}')

        if not api_key:
            # API í‚¤ê°€ ì—†ìœ¼ë©´ ê°„ë‹¨í•œ fallback íŒíŠ¸ ì œê³µ
            if not user_code or len(user_code.strip()) < 10:
                hint_response = "ë¨¼ì € ë¬¸ì œë¥¼ ë‹¨ê³„ë³„ë¡œ ë‚˜ëˆ„ì–´ ìƒê°í•´ë³´ì„¸ìš”. ì…ë ¥ì„ ì–´ë–»ê²Œ ì²˜ë¦¬í•˜ê³ , ì–´ë–¤ ì—°ì‚°ì„ í•´ì•¼ í• ê¹Œìš”?"
            else:
                hint_response = "ì‘ì„±í•˜ì‹  ì½”ë“œë¥¼ ë³´ë‹ˆ ì¢‹ì€ ì‹œì‘ì…ë‹ˆë‹¤! ë‹¤ìŒ ë‹¨ê³„ë¡œ, ì—£ì§€ ì¼€ì´ìŠ¤(ì˜ˆ: ë¹ˆ ì…ë ¥, ìµœì†Œê°’/ìµœëŒ€ê°’)ë¥¼ ê³ ë ¤í•´ë³´ì…¨ë‚˜ìš”?"
        else:
            try:
                headers = {
                    'Authorization': f'Bearer {api_key}',
                    'Content-Type': 'application/json'
                }
                # OpenAI í˜¸í™˜ Chat Completion í˜•ì‹ìœ¼ë¡œ ë³€ê²½ (2025ë…„ 7ì›”ë¶€í„° í•„ìˆ˜)
                payload = {
                    'model': ai_config.model_name,
                    'messages': [
                        {'role': 'system', 'content': 'ë‹¹ì‹ ì€ ì½”ë”© êµìœ¡ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 12ê°œ ì§€í‘œë¥¼ ëª¨ë‘ ë°˜ì˜í•˜ì—¬ JSON í˜•ì‹ìœ¼ë¡œ íŒíŠ¸ë¥¼ ë°˜í™˜í•´ì•¼ í•©ë‹ˆë‹¤.'},
                        {'role': 'user', 'content': prompt}
                    ],
                    'max_tokens': 1000,
                    'temperature': 0.7,
                    'top_p': 0.9
                }

                # Hugging Face Inference Providers (ìµœì‹  API)
                response = requests.post(
                    'https://router.huggingface.co/v1/chat/completions',
                    headers=headers,
                    json=payload,
                    timeout=30
                )

                if response.status_code == 200:
                    result = response.json()
                    # Chat Completion ì‘ë‹µ í˜•ì‹ ì²˜ë¦¬
                    if 'choices' in result and len(result['choices']) > 0:
                        llm_response_text = result['choices'][0]['message']['content'].strip()

                        # JSON íŒŒì‹± ì‹œë„
                        try:
                            llm_data = json.loads(llm_response_text)
                            hint_content = llm_data.get('hint_content', {})

                            # ì½”ë“œ ì˜ˆì‹œ ë“¤ì—¬ì“°ê¸° ë³´ì •
                            if hint_content.get('code_example'):
                                hint_content['code_example'] = format_code_indentation(hint_content['code_example'])

                            # íŒíŠ¸ ë‚´ìš© êµ¬ì„± (LLM ì§€í‘œëŠ” ì´ë¯¸ evaluate_code_with_llmì—ì„œ ê³„ì‚°ë¨)
                            hint_parts = []
                            if hint_content.get('summary'):
                                hint_parts.append(f"ğŸ’¡ {hint_content['summary']}")
                            if hint_content.get('libraries'):
                                hint_parts.append(f"ğŸ“š ì‚¬ìš© ë¼ì´ë¸ŒëŸ¬ë¦¬: {', '.join(hint_content['libraries'])}")
                            if hint_content.get('code_example'):
                                hint_parts.append(f"ğŸ“ ì½”ë“œ ì˜ˆì‹œ:\n{hint_content['code_example']}")
                            if hint_content.get('step_by_step'):
                                steps = '\n'.join(f"{i+1}. {step}" for i, step in enumerate(hint_content['step_by_step']))
                                hint_parts.append(f"ğŸ“‹ ë‹¨ê³„ë³„ ë°©ë²•:\n{steps}")
                            if hint_content.get('complexity_hint'):
                                hint_parts.append(f"â±ï¸ ë³µì¡ë„: {hint_content['complexity_hint']}")
                            if hint_content.get('edge_cases'):
                                cases = '\n'.join(f"- {case}" for case in hint_content['edge_cases'])
                                hint_parts.append(f"âš ï¸ ì—£ì§€ ì¼€ì´ìŠ¤:\n{cases}")
                            if hint_content.get('improvements'):
                                improvements = '\n'.join(f"- {imp}" for imp in hint_content['improvements'])
                                hint_parts.append(f"âœ¨ ê°œì„  ì‚¬í•­:\n{improvements}")

                            hint_response = '\n\n'.join(hint_parts) if hint_parts else "íŒíŠ¸ë¥¼ ìƒì„±í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

                        except json.JSONDecodeError:
                            # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì›ë¬¸ ë°˜í™˜
                            hint_response = llm_response_text
                    else:
                        hint_response = "íŒíŠ¸ë¥¼ ìƒì„±í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë¬¸ì œë¥¼ ë‹¤ì‹œ ì½ê³  ì˜ˆì œë¥¼ ë¶„ì„í•´ë³´ì„¸ìš”."
                else:
                    error_detail = response.text
                    print(f'Hugging Face API Error (Status {response.status_code}): {error_detail}')
                    hint_response = f"íŒíŠ¸ ìƒì„± ì‹¤íŒ¨ (ìƒíƒœ ì½”ë“œ: {response.status_code}). ë¬¸ì œì˜ ì…ì¶œë ¥ ì˜ˆì‹œë¥¼ ë¨¼ì € ë¶„ì„í•´ë³´ì„¸ìš”."
            except Exception as e:
                print(f'API Error: {str(e)}')
                hint_response = "íŒíŠ¸: ë¬¸ì œì˜ ì…ë ¥ê³¼ ì¶œë ¥ í˜•ì‹ì„ ë¨¼ì € íŒŒì•…í•˜ê³ , ë‹¨ê³„ë³„ë¡œ ë¡œì§ì„ êµ¬ì„±í•´ë³´ì„¸ìš”."

    elif ai_config.mode == 'local':
        # ë¡œì»¬ ëª¨ë“œ: ëª¨ë¸ì´ ë¡œë“œë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
        if not ai_config.is_model_loaded:
            hint_response = "ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”."
        else:
            hint_response = "[ë¡œì»¬ ëª¨ë¸] ë¬¸ì œë¥¼ ë‹¨ê³„ë³„ë¡œ ë‚˜ëˆ„ì–´ ìƒê°í•´ë³´ì„¸ìš”."

    elif ai_config.mode == 'runpod':
        # Runpod vLLM ëª¨ë“œ: OpenAI SDKë¥¼ ì‚¬ìš©í•˜ì—¬ vLLM ì„œë²„ì— ìš”ì²­
        try:
            from openai import OpenAI

            if not ai_config.runpod_endpoint:
                hint_response = "Runpod ì—”ë“œí¬ì¸íŠ¸ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”."
            else:
                # OpenAI í´ë¼ì´ì–¸íŠ¸ ìƒì„± (base_urlì„ Runpod ì—”ë“œí¬ì¸íŠ¸ë¡œ ì„¤ì •)
                client = OpenAI(
                    base_url=f"{ai_config.runpod_endpoint}/v1",
                    api_key=ai_config.runpod_api_key or "EMPTY"  # vLLMì€ API í‚¤ ë¶ˆí•„ìš”í•  ìˆ˜ ìˆìŒ
                )

                # Qwen 2.5 Coderì— ìµœì í™”ëœ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
                system_prompt = """You are Qwen, created by Alibaba Cloud. You are a helpful coding assistant specialized in:
- Code analysis and debugging
- Algorithm explanation
- Best practices in Python
- Step-by-step problem solving guidance

ë‹¹ì‹ ì€ ì½”ë”© êµìœ¡ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 12ê°œ ì§€í‘œë¥¼ ëª¨ë‘ ë°˜ì˜í•˜ì—¬ JSON í˜•ì‹ìœ¼ë¡œ íŒíŠ¸ë¥¼ ë°˜í™˜í•´ì•¼ í•©ë‹ˆë‹¤."""

                # vLLMì— Chat Completion ìš”ì²­
                response = client.chat.completions.create(
                    model=ai_config.model_name,
                    messages=[
                        {'role': 'system', 'content': system_prompt},
                        {'role': 'user', 'content': prompt}
                    ],
                    temperature=0.7,
                    top_p=0.9,
                    max_tokens=1000
                )

                # ì‘ë‹µ íŒŒì‹±
                llm_response_text = response.choices[0].message.content.strip()

                # JSON íŒŒì‹± ì‹œë„
                try:
                    llm_data = json.loads(llm_response_text)
                    hint_response = llm_data.get('hint', llm_response_text)

                    # LLM ì§€í‘œ ì—…ë°ì´íŠ¸
                    if 'metrics' in llm_data:
                        metrics_from_llm = llm_data['metrics']
                        llm_metrics['algorithm_efficiency'] = metrics_from_llm.get('algorithm_efficiency', 3)
                        llm_metrics['code_readability'] = metrics_from_llm.get('code_readability', 3)
                        llm_metrics['edge_case_handling'] = metrics_from_llm.get('edge_case_handling', 3)
                        llm_metrics['code_conciseness'] = metrics_from_llm.get('code_conciseness', 3)
                        llm_metrics['test_coverage_estimate'] = metrics_from_llm.get('test_coverage_estimate', 3)
                        llm_metrics['security_awareness'] = metrics_from_llm.get('security_awareness', 3)
                except json.JSONDecodeError:
                    # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì›ë³¸ í…ìŠ¤íŠ¸ ì‚¬ìš©
                    hint_response = llm_response_text

        except ImportError:
            hint_response = "OpenAI SDKê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. pip install openaië¥¼ ì‹¤í–‰í•˜ì„¸ìš”."
        except Exception as e:
            print(f'Runpod vLLM Error: {str(e)}')
            hint_response = f"Runpod ì—°ê²° ì˜¤ë¥˜: {str(e)}. ì—”ë“œí¬ì¸íŠ¸ URLê³¼ ë„¤íŠ¸ì›Œí¬ ì—°ê²°ì„ í™•ì¸í•˜ì„¸ìš”."

    else:
        hint_response = "ì•Œ ìˆ˜ ì—†ëŠ” AI ëª¨ë“œì…ë‹ˆë‹¤."

    # Save hint request to database
    try:
        problem_obj, _ = Problem.objects.get_or_create(
            problem_id=problem_id,
            defaults={
                'title': problem_title,
                'description': problem_description,
                'level': problem.get('level', 1),
                'step_title': problem.get('step_title', ''),
                'input_description': problem.get('input_description', ''),
                'output_description': problem.get('output_description', ''),
                'tags': problem.get('tags', []),
                'examples': problem.get('examples', []),
                'solutions': problem.get('solutions', [])
            }
        )

        model_used = f"{ai_config.get_mode_display()}: {ai_config.model_name}"
        HintRequest.objects.create(
            user=request.user,
            problem=problem_obj,
            hint_level=preset or 'custom',
            user_code=user_code or '(empty)',
            hint_response=hint_response,
            model_used=model_used
        )

        # HintMetrics ì €ì¥ (ì •ì  6ê°œ + LLM 6ê°œ)
        try:
            # ê¸°ì¡´ ë©”íŠ¸ë¦­ ê°€ì ¸ì˜¤ê±°ë‚˜ ìƒˆë¡œ ìƒì„±
            hint_metrics, created = HintMetrics.objects.get_or_create(
                user=request.user,
                problem=problem_obj,
                defaults={
                    # ì •ì  ì§€í‘œ
                    'syntax_errors': static_metrics['syntax_errors'],
                    'test_pass_rate': static_metrics['test_pass_rate'],
                    'code_complexity': static_metrics['code_complexity'],
                    'code_quality_score': static_metrics['code_quality_score'],
                    'algorithm_pattern_match': static_metrics['algorithm_pattern_match'],
                    'pep8_violations': static_metrics['pep8_violations'],
                    # LLM ì§€í‘œ
                    'algorithm_efficiency': llm_metrics['algorithm_efficiency'],
                    'code_readability': llm_metrics['code_readability'],
                    'design_pattern_fit': llm_metrics['design_pattern_fit'],
                    'edge_case_handling': llm_metrics['edge_case_handling'],
                    'code_conciseness': llm_metrics['code_conciseness'],
                    'function_separation': llm_metrics['function_separation'],
                    # ë©”íƒ€
                    'hint_count': 1,
                    'hint_config': hint_config
                }
            )

            if not created:
                # ê¸°ì¡´ ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
                hint_metrics.syntax_errors = static_metrics['syntax_errors']
                hint_metrics.test_pass_rate = static_metrics['test_pass_rate']
                hint_metrics.code_complexity = static_metrics['code_complexity']
                hint_metrics.code_quality_score = static_metrics['code_quality_score']
                hint_metrics.algorithm_pattern_match = static_metrics['algorithm_pattern_match']
                hint_metrics.pep8_violations = static_metrics['pep8_violations']
                hint_metrics.algorithm_efficiency = llm_metrics['algorithm_efficiency']
                hint_metrics.code_readability = llm_metrics['code_readability']
                hint_metrics.design_pattern_fit = llm_metrics['design_pattern_fit']
                hint_metrics.edge_case_handling = llm_metrics['edge_case_handling']
                hint_metrics.code_conciseness = llm_metrics['code_conciseness']
                hint_metrics.function_separation = llm_metrics['function_separation']
                hint_metrics.hint_count += 1
                hint_metrics.hint_config = hint_config
                hint_metrics.save()

            print(f'[Metrics Saved] User: {request.user.username}, Problem: {problem_id}')
            print(f'  ì •ì : syntax_errors={static_metrics["syntax_errors"]}, test_pass_rate={static_metrics["test_pass_rate"]}%, complexity={static_metrics["code_complexity"]}')
            print(f'  LLM: efficiency={llm_metrics["algorithm_efficiency"]}, readability={llm_metrics["code_readability"]}')

            # ë°°ì§€ íšë“ ì¡°ê±´ ì²´í¬
            try:
                newly_awarded = check_and_award_badges(request.user)
                if newly_awarded:
                    print(f'[New Badges] User: {request.user.username} earned {len(newly_awarded)} new badge(s): {[b.name for b in newly_awarded]}')
            except Exception as badge_error:
                print(f'Failed to check badges: {str(badge_error)}')

        except Exception as metric_error:
            print(f'Failed to save metrics: {str(metric_error)}')

    except Exception as e:
        print(f'Failed to save hint request: {str(e)}')

    # 7ë‹¨ê³„: ì‘ë‹µ ë°˜í™˜
    response_data = {
        'hint': hint_response,
        'problem_id': problem_id,
        'hint_purpose': hint_purpose,  # 'completion' or 'optimization'
        'static_metrics': static_metrics,
        'llm_metrics': llm_metrics
    }

    # optimizationì¸ ê²½ìš° ì•½í•œ ë©”íŠ¸ë¦­ ì •ë³´ í¬í•¨
    if hint_purpose == 'optimization' and weak_metrics:
        response_data['weak_metrics'] = [
            {'metric': metric_name, 'score': score, 'description': desc}
            for metric_name, score, desc in weak_metrics
        ]

    return Response({
        'success': True,
        'data': response_data
    })
