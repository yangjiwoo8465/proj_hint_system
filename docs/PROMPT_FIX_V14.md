# V14 - 2B 모델 + 코드 분석 프롬프트 (LLM 복귀)

## 결정: 템플릿 포기, 다시 LLM으로

### 템플릿의 근본적 한계 (V12-V13)

**사용자 피드백:**
> "템플릿을 만들어두기에는 문제의 수가 너무 많고,
> 사용자가 작성할 수 있는 코드의 흐름이 너무 다양해서
> LLM 모델이 직접 힌트를 생성하는 게 맞는 방법인 것 같아."

**템플릿의 한계:**
1. **확장성 부족** - 새 카테고리마다 템플릿 추가 필요
2. **다양성 제한** - 사전 정의된 질문만 가능
3. **복잡도 증가** - 문제 유형이 많아질수록 템플릿 관리 어려움
4. **창의성 없음** - 예상치 못한 상황 대응 불가

---

## V14 전략: 다시 LLM, 하지만 다르게

### 실패 원인 재분석 (V1-V11)

**V1-V11 실패 이유:**
1. ❌ **1.5B 모델 너무 작음** - Qwen2.5-1.5B, TinyLlama-1.1B
2. ❌ **프롬프트 너무 복잡** - 40줄+ 프롬프트, 금지사항 나열
3. ❌ **코드 컨텍스트 과다** - user_code 전체 제공 → Coder 모델 디버깅 모드
4. ❌ **예시 부적절** - 완전한 문장 예시 → 복사

**V14 개선 방향:**
1. ✅ **2B 모델 사용** - Gemma-2-2B, Phi-3.5-mini (더 크고 강력)
2. ✅ **초단순 프롬프트** - 15줄, 핵심만
3. ✅ **분석 결과만 제공** - 코드 대신 숫자 정보
4. ✅ **짧은 예시** - 단편적 예시, 패턴만

---

## 2B 모델의 장점

### 1.5B vs 2B 비교

| 항목 | 1.5B (Qwen2.5) | 2B (Gemma-2) | 3.8B (Phi-3.5) |
|------|----------------|--------------|----------------|
| **지시 이해** | 제한적 | 우수 | 매우 우수 |
| **패턴 학습** | 어려움 | 가능 | 잘함 |
| **일관성** | 낮음 | 중간 | 높음 |
| **속도** | 빠름 | 중간 | 느림 |
| **메모리** | ~3GB | ~4GB | ~2.5GB (4-bit) |

**선택:**
- **Gemma-2-2B-Instruct** - Google 품질, 2B
- **Phi-3.5-mini-Instruct** - Microsoft, 3.8B (4-bit)

---

## V14 프롬프트 설계

### 핵심 원칙

1. **짧게** - 15줄 이하
2. **숫자로** - 코드 대신 분석 결과
3. **예시로** - 짧고 명확한 패턴
4. **단순하게** - 복잡한 설명 제거

---

### V14 프롬프트 (전체)

```python
너는 학생에게 질문하는 선생님이야.

학생 상황:
- 지금까지: 일부 완료
- 아직 못함: {next_step_goal}
- 비슷한 코드: {similar_count}개
- if문: {if_count}개
- input: {input_count}번
- print: {print_count}번

질문 예시 (따라해):
1. "같은 작업 10번 해야 하는데 손으로?"
2. "나중에 바꾸면 5군데 다 고쳐?"
3. "입력 100개면 어떻게 처리?"

"{next_step_goal}" 못하면 어떤 문제?
한국어 반말로 짧은 질문 1개만.

질문:
```

**총 15줄**

---

### 구성 요소 분석

**1. 역할 (1줄)**
```
너는 학생에게 질문하는 선생님이야.
```
→ 명확한 역할 부여

---

**2. 학생 상황 (7줄)**
```
- 지금까지: 일부 완료
- 아직 못함: {next_step_goal}
- 비슷한 코드: 5개
- if문: 2개
- input: 3번
- print: 4번
```

→ **코드 대신 분석 결과** (핵심!)

**장점:**
- Coder 모델 디버깅 모드 회피
- 구체적 숫자로 맞춤형 가능
- 간결함

---

**3. 질문 예시 (4줄)**
```
1. "같은 작업 10번 해야 하는데 손으로?"
2. "나중에 바꾸면 5군데 다 고쳐?"
3. "입력 100개면 어떻게 처리?"
```

→ **짧은 패턴 예시**

**특징:**
- 완전한 문장 아님 (복사 방지)
- 물음표 포함 (형식 학습)
- 구체적 숫자 (패턴 강조)

---

**4. 직접 명령 (3줄)**
```
"{next_step_goal}" 못하면 어떤 문제?
한국어 반말로 짧은 질문 1개만.

질문:
```

→ **단순하고 직접적**

---

## V14 vs V11 프롬프트 비교

### V11 (Few-shot, 실패)

```python
질문 1개만 만들어.

학생이 "{next_step_goal}"를 못했음.

예시 1 - 반복:
질문: 같은 계산 10번 해야 하는데 매번 손으로?

예시 2 - 재사용:
질문: 나중에 숫자 바꾸면 10군데 다 고칠 건데?

예시 3 - 확장:
질문: 입력 100개면 어떻게 처리?

위처럼 "{next_step_goal}"에 대해 질문 1개. 물음표 필수.

질문:
```

**13줄**

**문제:**
- 1.5B 모델 = 패턴 학습 실패
- 코드 분석 정보 없음
- 결과: "어떤 문제 해결 방안을 제안할까요?" (막연함)

---

### V14 (코드 분석 + 2B)

```python
너는 학생에게 질문하는 선생님이야.

학생 상황:
- 비슷한 코드: 5개
- if문: 2개
- input: 3번

질문 예시:
1. "같은 작업 10번 해야 하는데 손으로?"
2. "나중에 바꾸면 5군데 다 고쳐?"

"{next_step_goal}" 못하면 어떤 문제?
질문:
```

**15줄**

**개선:**
- 2B 모델 = 패턴 학습 가능
- 코드 분석 정보 포함 (5개, 2개, 3번)
- 역할 명시 ("선생님")
- 기대: 맞춤형 소크라테스식 질문

---

## 코드 분석 → 프롬프트 흐름

### 1. 사용자 코드 분석

```python
code_analysis = self._analyze_user_code(user_code)

# 결과
{
    'similar_lines': ["print(...)", "print(...)", "print(...)"],
    'repeat_count': 5,
    'line_count': 10
}
```

---

### 2. 숫자 정보 추출

```python
similar_count = len(code_analysis['similar_lines'])  # 3
if_count = user_code.count('if ')  # 2
input_count = user_code.count('input(')  # 3
print_count = user_code.count('print(')  # 3
```

---

### 3. 프롬프트 생성

```python
prompt = f"""너는 학생에게 질문하는 선생님이야.

학생 상황:
- 비슷한 코드: {similar_count}개  # 3개
- if문: {if_count}개              # 2개
- input: {input_count}번           # 3번
- print: {print_count}번           # 3번

"{next_step_goal}" 못하면 어떤 문제?
질문:"""
```

---

### 4. 모델 추론

**2B 모델이 볼 수 있는 정보:**
- similar_count = 3 → "비슷한 코드 3개"
- next_step_goal = "함수 정의"

**기대 출력:**
```
"비슷한 코드 3개인데 나중에 바꾸면 3군데 다 고칠 건가?"
```

→ **맞춤형!**

---

## V1-V14 전체 여정

| 버전 | 모델 크기 | 프롬프트 전략 | 코드 분석 | 결과 |
|------|-----------|---------------|-----------|------|
| V1-V8 | 1.5B | 예시 제거, 규칙 | ❌ | 함수명 언급 |
| V9 | 1.5B | Logic Step | ❌ | 코드 디버깅 |
| V10 | 1.5B | 코드 제거 | ❌ | 함수명 언급 |
| V11 | 1.5B | Few-shot (13줄) | ❌ | 막연한 질문 |
| V12 | - | **템플릿** | ✅ | 일반적 질문 |
| V13 | - | **템플릿** | ✅ | 맞춤형 (한계) |
| **V14** | **2B** | **초단순 (15줄)** | **✅** | 테스트 필요 |

---

## 왜 V14가 성공할 것인가?

### 1. 더 큰 모델

**1.5B (V1-V11):**
- 복잡한 지시 이해 어려움
- 패턴 학습 제한적
- Few-shot도 실패

**2B (V14):**
- 지시 따르기 우수
- 패턴 학습 가능
- 더 일관된 출력

---

### 2. 코드 분석 정보

**Before (V1-V11):**
```python
# 막연한 정보
"학생이 {next_step_goal}를 못했음"
```

**After (V14):**
```python
# 구체적 정보
"비슷한 코드: 5개"
"if문: 2개"
```

→ 모델이 맞춤형 질문 생성 가능

---

### 3. 초단순 프롬프트

**V10 (43줄):** 너무 복잡
**V11 (13줄):** 여전히 복잡 (1.5B에게)
**V14 (15줄):** 2B 모델에게 적절

---

### 4. 짧은 예시

**Before:**
```
"같은 계산을 10군데에서 해야 하는데 코드 10번 복사할 건가?"
```
→ 완전한 문장 = 복사 우려

**After:**
```
"같은 작업 10번 해야 하는데 손으로?"
```
→ 짧은 패턴 = 학습 유도

---

## 기대 효과

### 시나리오 1: 반복 코드

**사용자 코드:**
```python
print(1 + 2)
print(2 + 3)
print(3 + 4)
print(4 + 5)
print(5 + 6)
```

**분석:**
- similar_count = 5

**프롬프트:**
```
비슷한 코드: 5개
아직 못함: 반복문 사용

질문 예시:
"같은 작업 10번 해야 하는데 손으로?"
```

**기대 출력:**
```
"비슷한 코드 5번 반복하는데 입력 100개면 어떻게 할 건데?"
```

---

### 시나리오 2: 함수 필요

**사용자 코드:**
```python
result1 = (a + b) * 2
result2 = (c + d) * 2
result3 = (e + f) * 2
```

**분석:**
- similar_count = 3

**프롬프트:**
```
비슷한 코드: 3개
아직 못함: 함수 정의

질문 예시:
"나중에 바꾸면 5군데 다 고쳐?"
```

**기대 출력:**
```
"비슷한 계산 3군데인데 나중에 바꾸면 3군데 다 고칠 건가?"
```

---

## 추천 모델

### 1순위: Gemma-2-2B-Instruct

**경로:** `google/gemma-2-2b-it`
**크기:** 2B
**특징:**
- Google 품질
- Instruction tuning 우수
- 안전한 출력

**예상 성능:** ⭐⭐⭐⭐

---

### 2순위: Phi-3.5-mini-Instruct

**경로:** `microsoft/Phi-3.5-mini-instruct`
**크기:** 3.8B (4-bit)
**특징:**
- Microsoft 품질
- 지시 따르기 최고
- 4-bit로 메모리 효율

**예상 성능:** ⭐⭐⭐⭐⭐

---

### 3순위: Qwen2.5-1.5B-Instruct

**경로:** `Qwen/Qwen2.5-1.5B-Instruct`
**크기:** 1.5B
**특징:**
- 한국어 지원
- 빠른 속도
- V11 실패 경험

**예상 성능:** ⭐⭐⭐ (개선 기대)

---

## 변경 사항

### 1. 모델 호출 복구

**V12-V13 (템플릿):**
```python
hint = self._create_analysis_prompt(user_code)
results = {model: {'hint': hint} for model in selected}
```

**V14 (LLM):**
```python
prompt = self._create_analysis_prompt(user_code)
results = self.model_manager.generate_hints_from_selected(
    prompt, selected, temperature
)
```

---

### 2. 프롬프트 생성

**V13 (템플릿 선택):**
```python
if "반복" in goal:
    return "같은 작업 10번..."
elif "함수" in goal:
    return "10군데 복사..."
```

**V14 (프롬프트 생성):**
```python
prompt = f"""
학생 상황:
- 비슷한 코드: {similar_count}개
- if문: {if_count}개

질문 예시:
"같은 작업 10번 해야 하는데 손으로?"

"{next_step_goal}" 못하면 어떤 문제?
질문:
"""
return prompt
```

---

## 장단점

### 장점 (vs 템플릿)

| 항목 | 템플릿 (V12-V13) | LLM (V14) |
|------|------------------|-----------|
| **확장성** | ❌ 수동 추가 | ✅ 자동 대응 |
| **다양성** | ❌ 고정 질문 | ✅ 무한 변형 |
| **창의성** | ❌ 없음 | ✅ 예상 못한 질문 |
| **복잡도** | ❌ 증가 | ✅ 일정 |

---

### 단점 (vs 템플릿)

| 항목 | 템플릿 | LLM |
|------|--------|-----|
| **일관성** | ✅ 100% | ⚠️ 90%? |
| **속도** | ✅ 0.001초 | ⚠️ 1-3초 |
| **품질 보장** | ✅ 확실 | ❓ 테스트 필요 |

---

## 결론

### 템플릿 포기 이유

1. **문제 수 너무 많음**
2. **코드 흐름 너무 다양**
3. **템플릿 관리 부담**
4. **창의성 필요**

### LLM 복귀 이유

1. **2B 모델 더 강력**
2. **코드 분석 정보 제공**
3. **초단순 프롬프트**
4. **무한 확장 가능**

### 기대

**V14 = V13(코드 분석) + 2B 모델 + 개선된 프롬프트**

→ **맞춤형 + 창의적 + 다양한 힌트**

---

## 변경 위치

**파일:** [hint-system/app.py](../hint-system/app.py)

**변경 함수:**
- `generate_hint()` (lines 251-259) - 모델 호출 복구
- `_create_analysis_prompt()` (lines 349-380) - V14 프롬프트

---

**작성일:** 2025-01-30
**버전:** V14 (LLM 복귀)
**이전 버전:** [PROMPT_FIX_V13.md](PROMPT_FIX_V13.md)
**핵심:** 템플릿 포기, 2B 모델 + 코드 분석 프롬프트
**철학:** "템플릿의 한계 < LLM의 가능성"
